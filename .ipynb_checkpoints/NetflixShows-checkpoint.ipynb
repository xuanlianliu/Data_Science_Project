{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b6fa92a-fb5d-4bda-ba79-c8589c63bcc9",
   "metadata": {},
   "source": [
    "# __FINAL PROJECT PHASE II__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cc71f8-040e-4b90-8ed7-cbea963dc1a6",
   "metadata": {},
   "source": [
    "# __RESEARCH QUESTION:__\n",
    "\n",
    "What set of criteria is most important to obtain the most viewership on Netflix from 2023 to 2025? Are we able to accurately predict viewership according to IMDb ratings and global availability? In the past two years, have films needed to be globally available in order to reach high popularity in terms of views of the movie?\n",
    "\n",
    "To elaborate on the set of criterias at hand, viewership is the number of hours that a user watched a movie for divided by the runtime in hours acccumulated in the provided and observed period in our Netflix engagment reports.  These reports are collected semi-annually.  IMDb ratings are out of 10 in ascending order where 1 is lowest and 10 is highest and collected by IMDb. Global availability is whether or not a movie is able to be watched in all countries with Netflix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c4b3df-c2f9-4a96-a29a-4172f535aca1",
   "metadata": {},
   "source": [
    "### Data Overview & Sources:\n",
    "\n",
    "In total, we collect seven data tables (linked below). The first five are taken from Netflix regarding semi-annual engagement reports starting from the first half of 2023 to the first half of 2025. Each report includes 2 tabs, (Shows and Films) or (Shows and Movies), and their respective data (i.e. runtime, viewership, global availability). The first half of 2023 report is an excpetion with only 1 tab of both shows and movies combined, but this gets handled in our data cleaning.\n",
    "\n",
    "Meanwhile, the following two IMDb data tables are combined to give us an extensive IMDb table to cross reference with the Netflix engagement reports. The IMDb ratings data table contains all the movies and shows, each identified by a unique ID that is not the movie/show title. The IMDb titles data table provides these IDs and the actual title, allowing us to link each movie/show's ratings with their title. \n",
    "\n",
    "Finally, we used some outside sources to help us with code, and these sources are cited within their code cell.\n",
    "\n",
    "Source for Netflix Engagement Report First Half 2023: https://about.netflix.com/en/news/what-we-watched-a-netflix-engagement-report\n",
    "\n",
    "Source for Netflix Engagement Report Second Half 2023: https://about.netflix.com/en/news/what-we-watched-the-second-half-of-2023\n",
    "\n",
    "Source for Netflix Engagement Report First Half 2024: https://about.netflix.com/en/news/what-we-watched-the-first-half-of-2024\n",
    "\n",
    "Source for Netflix Engagement Report Second Half 2024: https://about.netflix.com/en/news/what-we-watched-the-second-half-of-2024\n",
    "\n",
    "Source for Netflix Engagement Report First Half 2025: https://about.netflix.com/en/news/what-we-watched-the-first-half-of-2025\n",
    "\n",
    "Source of IMDb Ratings for Movies/Shows: https://datasets.imdbws.com/title.ratings.tsv.gz\n",
    "\n",
    "Source of IMDb Movie/Show Titles: https://datasets.imdbws.com/title.basics.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3d2ad4-4778-4e55-8427-4afedaa5950a",
   "metadata": {},
   "source": [
    "### Importing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dcf011d-20dc-48a4-b38d-8018f9449014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import duckdb\n",
    "from datetime import time\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3413e42b-affb-4e5a-9d91-632a5a02bc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/2950/lib/python3.13/site-packages (2.3.2)\n",
      "Requirement already satisfied: openpyxl in /opt/anaconda3/envs/2950/lib/python3.13/site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/envs/2950/lib/python3.13/site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/2950/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/2950/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/2950/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: et-xmlfile in /opt/anaconda3/envs/2950/lib/python3.13/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/2950/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c754bd-377d-48c8-84d5-006787c525ff",
   "metadata": {},
   "source": [
    "# __Data Collection & Cleaning:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6984b98-03ed-425b-b684-63cc6ad39003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the dataset with all ratings from IMBb. \n",
    "#note that each rating has a unique ID, not the show/movie title\n",
    "ratings_df= pd.read_table(\"title.ratings.tsv\")\n",
    "\n",
    "#import the dataset with movie title given the ID\n",
    "titles_df= pd.read_table(\"title.basics.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae1feff-0021-4406-8a3d-7a4ac955c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform an SQL join to obtain a dataframe with the rating, number of votes for that rating, and title\n",
    "merged_ratings_df= duckdb.sql(\"\"\"SELECT r.tconst, r.averageRating, r.numVotes,\n",
    "t.originalTitle AS Title\n",
    "FROM ratings_df r, titles_df t\n",
    "WHERE r.tconst=t.tconst\"\"\").df()\n",
    "\n",
    "#drop the duplicate titles to prevent duplicate rows when merging with Netflix dataframe\n",
    "merged_ratings_df = merged_ratings_df.drop_duplicates(subset=['Title'])\n",
    "\n",
    "#look at the merged_ratings_df\n",
    "#merged_ratings_df.to_csv(\"merged_ratings_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b9a484-5f20-4f14-a3fd-1fea6c3eb51a",
   "metadata": {},
   "source": [
    "We observe that in merged_ratings_df, the movie titles are truly titles, which is what we expected. However, many rows do not have show titles, only episode numbers. For example, the observation with the ID of tt0740721 has the corresponding Title, Episode #1.1.  \n",
    "We attempted to fix this problem with show titles by looking for IMDb dataset(s) that would let us link the ID and episode number with a show title. We found another IMDb source, title.akas.tsv, that was stated to have the ID and title of the show, but after reading it in, we realized it did not provide the true titles. We then found another IMDb source, title.episode.tsv, that provided the ID, the show's season and episode number, and another parent ID. However, we could not locate the data source allowing us to reference the parent ID with the title. At this point, we made the decision to proceed with films only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4c912d-721f-4d2a-b367-bbde4c7fd66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the netflix engagement reports\n",
    "#import 1st half of 2023 netflix data\n",
    "all_jan_jun_2023= pd.read_excel(\"What_We_Watched_A_Netflix_Engagement_Report_2023Jan-Jun.xlsx\",\n",
    "                                  sheet_name=\"Engagement\",\n",
    "                                  skiprows=5)\n",
    "\n",
    "#import 2nd half of 2023 netflix data\n",
    "movies_jul_dec_2023= pd.read_excel(\"What_We_Watched_A_Netflix_Engagement_Report_2023Jul-Dec.xlsx\",\n",
    "                                  sheet_name=\"Film\",\n",
    "                                  skiprows=5)\n",
    "\n",
    "#import the 1st half of 2024 netflix data\n",
    "movies_jan_jun_2024= pd.read_excel(\"What_We_Watched_A_Netflix_Engagement_Report_2024Jan-Jun.xlsx\",\n",
    "                                   sheet_name= \"Film\",\n",
    "                                   skiprows=5)\n",
    "\n",
    "#import the 2nd half of 2024 netflix data\n",
    "movies_jul_dec_2024= pd.read_excel(\"What_We_Watched_A_Netflix_Engagement_Report_2024Jul-Dec.xlsx\",\n",
    "                                   sheet_name= \"Film\",\n",
    "                                   skiprows=5)\n",
    "movies_jul_dec_2024['Time_Period']= \"2024 H2\"\n",
    "#import the 1st half of 2025 netflix data\n",
    "movies_jan_jun_2025= pd.read_excel(\"What_We_Watched_A_Netflix_Engagement_Report_2025Jan-Jun.xlsx\",\n",
    "                                   sheet_name= \"Movies\",\n",
    "                                   skiprows=5)\n",
    "\n",
    "#source used to figure out how to skip rows when importing Excel sheet:\n",
    "#https://www.statology.org/pandas-read-excel-skip-rows/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e7b87c-f649-4f19-985a-b7f68f358d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the time periods of the observations\n",
    "all_jan_jun_2023['Time_Period']= \"2023 H1\"\n",
    "movies_jul_dec_2023['Time_Period']= \"2023 H2\"\n",
    "movies_jan_jun_2024['Time_Period']= \"2024 H1\"\n",
    "movies_jan_jun_2025['Time_Period']= \"2025 H1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606e8db-dc2f-4c6b-8096-658497773143",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all these dataframes into 1 Netflix dataframe, named netflix_df\n",
    "#note that the Release Date has several missing values and thus omit it\n",
    "netflix2023= duckdb.sql(\"\"\"SELECT \n",
    "                    Title, \n",
    "                    \"Available Globally?\" AS Global, \n",
    "                    \"Hours Viewed\" AS Hours_Viewed, \n",
    "                    Runtime, Views, Time_Period\n",
    "                FROM movies_jul_dec_2023 \n",
    "                UNION \n",
    "                SELECT\n",
    "                    Title, \n",
    "                    \"Available Globally?\" AS Global, \n",
    "                    \"Hours Viewed\" AS Hours_Viewed, \n",
    "                    NULL AS Runtime, \n",
    "                    NULL AS Views, Time_Period\n",
    "                FROM all_jan_jun_2023\"\"\").df()\n",
    "\n",
    "print(netflix2023.shape)\n",
    "\n",
    "jan_jun_2024= duckdb.sql(\"\"\"SELECT\n",
    "                                Title, \n",
    "                                \"Available Globally?\" AS Global, \n",
    "                                \"Hours Viewed\" AS Hours_Viewed, \n",
    "                                Runtime, Views, Time_Period\n",
    "                            FROM movies_jan_jun_2024\"\"\").df()\n",
    "\n",
    "jul_dec_2024= duckdb.sql(\"\"\"SELECT\n",
    "                                Title, \n",
    "                                \"Available Globally?\" AS Global, \n",
    "                                \"Hours Viewed\" AS Hours_Viewed, \n",
    "                                Runtime, Views, Time_Period\n",
    "                            FROM movies_jul_dec_2024\"\"\").df()\n",
    "\n",
    "netflix2024= duckdb.sql(\"\"\"SELECT * FROM jan_jun_2024 UNION ALL SELECT * FROM jul_dec_2024\"\"\").df()\n",
    "#print(len(movies_jan_jun_2024) + len(movies_jul_dec_2024))\n",
    "print(netflix2024.shape)\n",
    "\n",
    "netflix2025= duckdb.sql(\"\"\"SELECT\n",
    "                                Title, \n",
    "                                \"Available Globally?\" AS Global, \n",
    "                                \"Hours Viewed\" AS Hours_Viewed, \n",
    "                                Runtime, Views, Time_Period\n",
    "                            FROM movies_jan_jun_2025\"\"\").df()\n",
    "\n",
    "\n",
    "print(netflix2025.shape)\n",
    "\n",
    "netflix_df= duckdb.sql(\"\"\"SELECT * FROM netflix2023 UNION SELECT * FROM netflix2024 UNION SELECT * \n",
    "FROM netflix2025\"\"\").df()\n",
    "\n",
    "print(netflix_df.shape)\n",
    "\n",
    "#UNION operator source: https://www.w3schools.com/sql/sql_union.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5da4acd-48af-4e54-8a09-9003c20d6b79",
   "metadata": {},
   "source": [
    "At this point, we have created a dataframe, netflix_df, that includes every film's viewership from the start of 2023 until the first half of 2025. We also printed the shapes of every dataframe to confirm that the netflix_df equals the sum of each year's number of observations.  \n",
    "Next, we want to match each film with its IMDb rating, if a rating exists. Unfortunately, the Netflix and IMDb sources do not have a standardized convention for their film titles. In the following several code cells, we make an effort to clean the titles as much as possible, to improve the number of matches when we merge the Netflix and ratings dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faccb3bc-906a-4952-9162-ab389d4ea4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Netflix films with foreign language titles have both english translation then the foreign title\n",
    "#cut the title of netflix shows with foreign language titles, keeping the english title only\n",
    "mod_title= netflix_df['Title']\n",
    "mod_title= mod_title.str.replace(r\" \\/\\/.*\", \"\", regex=True)\n",
    "\n",
    "netflix_df['Title']= mod_title\n",
    "\n",
    "#check that the foreign language component is gone\n",
    "#netflix_df.head()\n",
    "\n",
    "#I previously did similar work with meta characters and string detect/string replace in R,\n",
    "#but I used help with the string replace:\n",
    "#https://stackoverflow.com/questions/5658369/how-to-input-a-regex-in-string-replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe240a1-caf4-4b4f-829b-1cfef7cf25a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at netflix titles\n",
    "netflix_df.to_csv(\"netflix_titles.csv\", index=False)\n",
    "merged_ratings_df.to_csv(\"imdb_titles.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef0d829-7c44-4ca2-bd58-72aa336377fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some Netflix titles end with the year in parenthesis, which is not seen in ratings titles\n",
    "\n",
    "year_tester= netflix_df[\"Title\"].str.endswith(\")\")\n",
    "\n",
    "#removing the last 6 characters cuts the (Year) component if it is at the end of the title\n",
    "netflix_df.loc[year_tester, \"Title\"]= netflix_df.loc[year_tester, \"Title\"].str[:-6]\n",
    "\n",
    "#check that the (Year) component is gone\n",
    "#year_tester_2= netflix_df[\"Title\"].str.endswith(\")\")\n",
    "#netflix_df[year_tester_2].head()\n",
    "\n",
    "#source used for the str.endswith:\n",
    "#https://www.w3schools.com/python/ref_string_endswith.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d96f29-54a0-4824-8349-9918ee3ef435",
   "metadata": {},
   "source": [
    "The netflix_df will now have more matches with the merged_ratings_df. We will now merge the two datasets with an INNER JOIN so that only the netflix films with ratings in IMDb are kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e21b215-c685-4169-8165-80b80ae89eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inner join Netflix and ratings datasets\n",
    "netflix_ratings_df= duckdb.sql(\"\"\"SELECT netflix_df.Title, netflix_df.Global, \n",
    "netflix_df.Hours_Viewed, netflix_df.Runtime, netflix_df.Views, netflix_df.Time_Period, \n",
    "merged_ratings_df.averageRating, merged_ratings_df.numVotes\n",
    "FROM netflix_df\n",
    "INNER JOIN merged_ratings_df\n",
    "ON netflix_df.Title= merged_ratings_df.Title\n",
    "\"\"\").df()\n",
    "print(netflix_ratings_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dce76a-5c01-4a4e-a78a-225a403c4617",
   "metadata": {},
   "source": [
    "Next, we will clean the netflix_ratings_df to make it ready for analysis. Please see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bb1455-129d-4fee-9452-429e87bd934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping by titles to drop the duplicates.\n",
    "#Taking the row with the maximum views because this is the row with peak popularity \n",
    "netflix_ratings_df = netflix_ratings_df.sort_values(by=[\"Views\"], ascending=False)\n",
    "netflix_ratings_df = netflix_ratings_df.drop_duplicates([\"Title\"], keep=\"first\")\n",
    "print(f\"Our dataset has {netflix_ratings_df.shape[0]} number of films\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c8ca51-1845-4835-8400-e4f48c78a545",
   "metadata": {},
   "source": [
    "The 2023 data only has hours viewed, not viewership. We will fill the missing values with the hours viewed divided by the average runtime. We are choosing to do this so that we do not have to drop the 2023 data nor have empty data values.  \n",
    "The Hours Viewed has the accurate data, and dividing it by the average runtime which is a constant means the transformation is not skewed. The average runtime is the best choice to transform the hours viewed because the runtime of a movie is unlikely to be extremely different in 2023-2025 compared to just 2023. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e531994c-e9a2-4284-bca9-960bae7e6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making time column to have type time, then adjusting runtime to be in minutes\n",
    "netflix_ratings_df[\"Runtime\"] = pd.to_datetime(netflix_ratings_df['Runtime'], format='%H:%M')\n",
    "netflix_ratings_df[\"Runtime\"] = netflix_ratings_df[\"Runtime\"].dt.hour*60 + netflix_ratings_df[\"Runtime\"].dt.minute\n",
    "\n",
    "#Finding average runtime and plugging it in to the missing values of runtime without skewing the data \n",
    "#to complete the dataframe enabling us to make future analysis\n",
    "avgRuntime = np.round(np.mean(netflix_ratings_df[\"Runtime\"]))\n",
    "isEmptyRuntime = netflix_ratings_df[\"Runtime\"].isna()\n",
    "netflix_ratings_df.loc[isEmptyRuntime, \"Runtime\"] = avgRuntime\n",
    "\n",
    "#Calculating views for empty values for Views column using runtime and hours viewed\n",
    "isEmptyViews = netflix_ratings_df[\"Views\"].isna()\n",
    "netflix_ratings_df.loc[isEmptyViews, \"Views\"] = netflix_ratings_df[\"Hours_Viewed\"]/np.round(avgRuntime/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89df9c2-dbba-460d-93ee-eb02bf3d373a",
   "metadata": {},
   "source": [
    "To finish the dataset preparation, we will create a couple more columns to be used in future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63326b0-2e17-4dbf-804b-5349c497460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new columns to use in future binary analysis on global avaiability \n",
    "netflix_ratings_df[\"Is_Global\"] = netflix_ratings_df[\"Global\"].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "#create new column that determines popularity based on being above and below average views\n",
    "netflix_ratings_df[\"Popularity\"] = netflix_ratings_df[\"Views\"] > np.mean(netflix_ratings_df[\"Views\"])\n",
    "netflix_ratings_df[\"Popularity\"] = netflix_ratings_df[\"Popularity\"].map({True: int(1), False: int(0)})\n",
    "\n",
    "#create new column that determines the number of reviews (numVotes) to be greater than or less than the median\n",
    "netflix_ratings_df[\"Sufficient Votes\"] = netflix_ratings_df[\"numVotes\"] > np.median(netflix_ratings_df[\"numVotes\"])\n",
    "netflix_ratings_df[\"Sufficient Votes\"] = netflix_ratings_df[\"Sufficient Votes\"].map({True: int(1), False: int(0)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5123a454-2eea-4770-bb05-3646fd99e6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look at our cleaned dataset\n",
    "print(netflix_ratings_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69e1117-eb10-4b76-acc0-6ce602711e7e",
   "metadata": {},
   "source": [
    "# __Data Description:__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e00c1a-ec2d-4798-bc1f-15dcc4651af7",
   "metadata": {},
   "source": [
    "Our dataframe was created by joining multiple Netflix engagement reports from different periods and merged with the IMDb ratings dataset to observe if any factors had the most influence on viewership for Netflix films and predict viewership for films outside of the dataset according to observed criteria. The cleaned dataset for analysis consists of 8772 Netflix films watched from January 2023 to June 2025, along with their respective attributes in terms of global availability, hours viewed, runtime, views, average IMDb rating, number of votes (defined in the next cell).\n",
    "\n",
    "All source datasets used during this phase and their creation were funded by either Netflix or IMDb. In the earliest engagement report, Netflix states that the dataset representing 99% of all viewing on Netflix, so there is low concern that data is not recorded. Because IMDb ratings are made by users, it is possible that the most recent movies or those with low audience engagement are not observed in the IMDb source dataset. However, these concerns have little impact on our cleaned dataset, which spans until June of 2025 which is 4 months ago and only has movies with over 100,000 Netflix views (thus likely getting some ratings). Both Netflix viewers and IMDb reviewers should reasonably know that their behavior is tracked, although they may not know their data would be used to make these public datasets. Fot Netflix viewers, Netflix recommends shows based off of previous titles watched, so users know their watching is monitored. For IMDb reviewers, everyone's ratings are public on the site, so they know their ratings are not private. We do not forsee a notable change in viewing or rating behavior due to the fact that people consider that their data gets collected for a dataset. \n",
    "\n",
    "As a whole, both the Netflix and IMDb original data sources were preprocssed into (mostly) consistent datasets, but the column names were not consistent with each other. Our original plan was to create a dataset containing both Netflix films and shows, but upon merging with the IMDb dataset, we discovered that many shows were missing rating information and so we decided to focus solely on films. This meant reducing our dataset, but given that we are still able to work with around 8,772 instances of films, we should have sufficient data for performing exploratory analysis. We decided to retain the majority of the attributes found in both the Netflix and IMDb datasets since our research aims to identify which factors most strongly influence viewership. Removing such attributes could limit the scope of our findings later on.\n",
    "\n",
    "Much of the data cleaning that was performed using SQL. Our first task involved merging the IMDb datasets together, as title.ratings.tsv only contains ratings corresponding to an ID and not a film title while title.basics.tsv includes the corresponding film title along with their respective IDs. By performing a SQL join on these two datasets, we obtained a single dataframe containing both film titles and their ratings. \n",
    "\n",
    "The second task was to combine all of Netflix’s semi-annual engagement datasets into a master dataset. Using the UNION ALL operator in SQL, we were able to successfully retain all instances from all four datasets. During this process, we also noticed that some Netflix films contained titles in their original languages which would be a problem when merging with the IMDb dataset that only has titles in English. To ensure consistent title matching, we cleaned up the film titles by removing the extra info that followed // by simply replacing a part of the title string with an empty string. Additionally, for titles that had it, we cleaned the film titles by removing the year in parenthesis.\n",
    "\n",
    "Once that was done, we performed an inner join between our Netflix and IMDb datasets using the shared column Title. This join type allowed us to keep only instances of the Netflix dataset with corresponding IMDb data, so our dataset would not have missing rating values. \n",
    "\n",
    "Additionally, we created dummy variables like Is_Global and Popularity, to support our exploratory analysis. The Is_Global variable was encoded as 1 for films globally available and 0 for unavailable. The column, Popularity, that marked whether a film had more than the median views was created and then converted into a binary variable with 1 being popular and 0 for not popular.\n",
    "\n",
    "All raw source data can be found on the Github folder which can also be accessed here. \n",
    "https://github.com/xuanlianliu/Data_Science_Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8495be13-1627-469d-8f27-b39a7765c047",
   "metadata": {},
   "source": [
    "Further definitions of our columns:  \n",
    "Title: the title of the film (must match in both Netflix and IMDb)  \n",
    "Global: either \"Yes\" or \"No\" to the film's ability to be watched in all countries with Netflix  \n",
    "Hours_Viewed: the number of hours the film was watched, accumulated in the time period  \n",
    "Runtime: the length of the film  \n",
    "Views: the Hours_Viewed multiplied by the Runtime  \n",
    "Time_Period: the time interval in which the viewership data was collected. Is measured semi-annually, either Jan-Jun or Jul-Dec  \n",
    "average_Rating: the rating given by IMDb users, out of 10 in ascending order where 1 is lowest and 10 is the highest  \n",
    "numVotes: the number of votes cast for the film  \n",
    "Is_Global: measures global availibility, encoded as 1 for films globally available and 0 for unavailable  \n",
    "Popularity: measures whether a film had more than the median views was created, encoded as 1 being popular and 0 for not popular  \n",
    "Sufficient Votes: measures whether a film recieved sufficient votes, defined as more than the median number of votes, encoded as 1 being sufficient votes and 0 for not sufficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96787bc1-84ed-4677-930a-97e1ad30cd54",
   "metadata": {},
   "source": [
    "# __Data Limitations:__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14aef76-3301-47f9-827d-601cc19ab155",
   "metadata": {},
   "source": [
    "There were several limitations we discovered in our dataset. \n",
    "- The Netflix source began with a release date column, which were missing many values, so we ultimately chose not to include this variable in our dataset. However, this exacerbates our time interval limitation: our dataset only covers a 2.5-year period worth of Netflix data spanning from January 2023 to June 2025. This short timeframe might make it hard for us to generalize our findings to other years and their films and may affect the accuracy of our predictive models. Additionally, the first half of 2023 dataset was missing 2 important variables: runtime and number of views. We filled these missing columns with their respective averages but this approach risks suggesting a consistent pattern across all the first half of 2023 films. While the missing values have been addressed, these are not exactly the true runtime and view values which could cause some discrepancies in our data analysis. In the graph of views over time, the aggregate views in 2023 is significantly lower than in each later period. We believe the reason for this unusual result is the lack of full data in the source for the first half of 2023.\n",
    "- Our Netflix dataset contains duplicates of certain films as they appeared in multiple engagement reports during collection. To address this, we removed the duplicates and kept only the instance with its max views. Such removal might reduced the total number of views for certain Netflix time periods and alter our observations of viewership over time.\n",
    "- We also experienced limitations from the ratings dataset. Not every Netflix title matches with an IMDb rating, so there are many missing ratings. This harms our predictions of viewership based on ratings because many films are missing from the analysis. Specifically when considering naming across Netflix and IMDb, we think the titles with complex titles and those with alternate release names in different regions are most likely to not have exact matches between Netflix and IMDb, due to formatting inconsistencies. This could affect the analysis by disproportionately reducing the number of regional films compared to international, widespread films, making it appear that regional films are less watched than in reality.\n",
    "- Other limitations arise from the fact that anyone on IMDb can rate a film. Not all reviews are the same quality because there is no verification of whether or not they truly watched the film or have external motives (e.g., review bombing for personal enjoyment or rating highly just because their favorite actor is in it). This could impact our analysis by creating trends that do not exist from those who did not watch the movie as a genuine viewer. In addition, people who rated films on IMDb may have watched them in ways other than Netflix. In other words, the ratings bring in people who are not related with Netflix into our cleaned dataset, so our analysis could be inaccurate if the Netflix reviewers think differently compared to non-Netflix reviewrs.\n",
    "- We observe variation in the number of votes that determined each film’s IMDb rating. Films with a smaller number of votes could skew the rating, which could ultimately affect our analysis of how ratings correlate with viewership.\n",
    "- Mainstream movies are likely to garner more viewership than indie movies overall. Since we took the average of views to determine the baseline for what makes a movie popular, it means that many mainstream movies will automatically be considered popular because of their high view count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a94654b-100e-4171-95ce-d9f71ca2716b",
   "metadata": {},
   "source": [
    "# __Exploratory Data Analysis:__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc8bd88-8fd3-4cd1-95a3-614e79ddbdbf",
   "metadata": {},
   "source": [
    "### Movie Viewership based on Ratings and Global Availability:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3200ca9-812e-4114-a1d3-559a5d7efc6d",
   "metadata": {},
   "source": [
    "Linear Regression (x - ratings, y - viewership), Avg Views on each rating as bar graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d504ad-e75c-4a10-977a-45438618b869",
   "metadata": {},
   "source": [
    "To help gauge whether or not there is a relationship between Views and Ratings and the relationship between Views and Global Availability, we need a series of graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a2d8a4-7889-445d-a993-cda1c0cbb44b",
   "metadata": {},
   "source": [
    "Conduct a scatterplot analysis on the number of views for a movie based on the ratings and global availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fa550e-ad46-491c-954e-fb64faf2c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.scatterplot(netflix_ratings_df, \n",
    "             x='averageRating', y='Views', marker='o', hue=\"Global\")\n",
    "plt.title(\"Number of Views based on Ratings\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1823e95b-cffb-4bd4-adfa-d09376be494b",
   "metadata": {},
   "source": [
    "Conduct a scatterplot analysis on the hours viewed for a movie based on the ratings and global availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1786438a-eb4e-4167-b38d-17833fb8df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.scatterplot(netflix_ratings_df, \n",
    "             x='averageRating', y='Hours_Viewed', marker='o', hue=\"Global\")\n",
    "plt.title(\"Hours Viewed based on Ratings\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c25843-4e90-4cd1-ab56-64293e5cc60a",
   "metadata": {},
   "source": [
    "### Movie Viewership over Time:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffce1467-281c-4cff-a3f7-cf683af34d30",
   "metadata": {},
   "source": [
    "The below graph is to build an understanding of how much time (in hours) is spent watching films in each time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18466848-7924-4a8f-a5f4-121ed9c06041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the total views per each time period\n",
    "netflix_summarized= duckdb.sql(\"\"\"SELECT Time_Period,\n",
    "SUM(Views) as Total_Views,\n",
    "FROM netflix_ratings_df\n",
    "WHERE Views IS NOT NULL\n",
    "GROUP BY Time_Period\n",
    "ORDER BY Time_Period ASC\"\"\").df()\n",
    "\n",
    "#graph the views over time with a scatterplot\n",
    "viewership_plot= plt.plot(netflix_summarized['Time_Period'], netflix_summarized['Total_Views'], 'o')\n",
    "plt.title(\"Views over Time\")\n",
    "plt.xlabel('Time Period')\n",
    "plt.ylabel('Hours Viewed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ad5604-55e8-4c1d-adac-caac874cc668",
   "metadata": {},
   "source": [
    "The above graph shows that Netflix subscribers greatly increased their viewership from first half of 2023 to the second half of 2024, watching 6 times as many hours. Logically, this result is not realistic, and we will discuss possible reasons why in the limitations section. \n",
    "The below graph shows the top films and their views by the time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e6316-d52c-43de-9460-7e246669df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 100 films\n",
    "\n",
    "netflix_top_100= duckdb.sql(\"\"\"SELECT *\n",
    "FROM netflix_ratings_df\n",
    "WHERE Views IS NOT NULL\n",
    "ORDER BY Views DESC\n",
    "LIMIT 100\"\"\").df()\n",
    "\n",
    "#graph the top 100 films\n",
    "#top_100_plot= sns.scatterplot(netflix_top_100, x= \"Ratings\", y= \"Views\", market= \"o\", hue=\"Global\")\n",
    "#top_100_plot= plt.plot(netflix_top_100['Time_Period'], netflix_top_100['Views'], 'o')\n",
    "#plt.title(\"Top 100 Films\")\n",
    "#plt.show()f\n",
    "\n",
    "g=sns.FacetGrid(netflix_top_100, col=\"Time_Period\")\n",
    "g.map_dataframe(sns.histplot, x=\"Views\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf6b861-85d5-4c85-8170-f1b97f320335",
   "metadata": {},
   "source": [
    "### Correlation and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b98cfa-43ba-45de-845a-f06abe835dbf",
   "metadata": {},
   "source": [
    "Now, we will create a multi-variable correlation matrix to examine the strength and directions of relationships with the following variables: Views, Hours Viewed, Runtime, Global Availability, Average Rating, Number of Votes, and Popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e94396-6896-4e6e-b270-5fc3df9692af",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = netflix_ratings_df[['Views', 'Hours_Viewed', 'Runtime', 'Is_Global', 'averageRating', 'numVotes', 'Popularity']].corr()\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860b67e8-52ff-40ac-aa13-4a21c0711052",
   "metadata": {},
   "source": [
    "The correlation matrix displays a very high correlation, 0.98, between Views and Hours Viewed, and this clearly makes sense because being viewed (the number of views) is linked with being viewed (in hours). We also observe a positive correlation of 0.20 between Views and being globally available, a positive correlation of 0.02 between Views and Average Rating, a postive correlation of 0.07 between Views and Number of Votes, and 0.51 between Views and Popularity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25f5c6-2aa1-4638-992f-ebe1cd11bbfe",
   "metadata": {},
   "source": [
    "We will fit a linear regression model predict view counts given the ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f01cbdf-4924-4380-b346-44874dfa4149",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_nan_df = netflix_ratings_df.copy().dropna()\n",
    "x = no_nan_df[['averageRating']].values\n",
    "y = no_nan_df[['Views']].values\n",
    "\n",
    "ratings_model = LinearRegression().fit(x,y)\n",
    "print(\"The model's slope is: \" + str(round(float(ratings_model.coef_[0][0]),2)))\n",
    "print(\"The model's intercept is: \" + str(round(float(ratings_model.intercept_[0]),2)))\n",
    "\n",
    "no_nan_df[\"View_Pred\"] = ratings_model.predict(x)\n",
    "plot2 = sns.scatterplot(no_nan_df, \n",
    "             x='averageRating', y='View_Pred')\n",
    "plt.title(\"View Predictions Based on Ratings\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8819a0-a0ed-4563-8fa0-a58807c28e41",
   "metadata": {},
   "source": [
    "We will fit a logistic regression model to determine the coefficient and intercept to see how the odds of the popularity change for each unit of increase in ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771049ac-b232-4c46-890a-7fae64fe23e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = netflix_ratings_df['averageRating'].values.reshape(-1, 1)\n",
    "y = netflix_ratings_df['Popularity']\n",
    "model = LogisticRegression().fit(x,y)\n",
    "\n",
    "print(model.coef_[0][0])\n",
    "print(model.intercept_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f05fa2-2cf4-4a2f-bc7c-fb709e60d491",
   "metadata": {},
   "source": [
    "Using the model's predict_proba, we can find the probability of a movie being successful based on the average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca50a5-e5a8-4cd0-a01d-8455828ccc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_ratings_df['popularity_pred'] = model.predict_proba(netflix_ratings_df[['averageRating']].values)[:, 1]\n",
    "sns.scatterplot(x = netflix_ratings_df['averageRating'], y = netflix_ratings_df['popularity_pred'], hue = netflix_ratings_df['Popularity'])                                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9522c8-b63b-422b-a570-d65e87943788",
   "metadata": {},
   "source": [
    "The graph below allows us to visualize how the number of votes changes in relation to the average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d7e46f-9002-4429-87c7-6ab200d79376",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(netflix_ratings_df, x = 'averageRating', y= 'numVotes', hue='Sufficient Votes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655fab0d-2a7b-46f8-8f32-f2a4e088e164",
   "metadata": {},
   "source": [
    "### Global Availability Pie Charts:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ead66f-4f69-4abe-aff6-954c4976aa65",
   "metadata": {},
   "source": [
    "The following pie charts are meant to visualize the bearing that the trait of global analysis has on popularity. Findings are stated at the end of this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf54f65-084f-4fc6-8233-4f6545cdab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 100 viewed films by global availability\n",
    "yes_count = (netflix_top_100[\"Global\"]==\"Yes\").sum()\n",
    "no_count  = (netflix_top_100[\"Global\"]==\"No\").sum()\n",
    "\n",
    "y = np.array([yes_count, no_count])\n",
    "mylabels = [\"Global\", \"Not Global\"]\n",
    "\n",
    "plt.pie(y, labels = mylabels)\n",
    "plt.title(\"Global Availability of Top 100 Most-Watched Films\")\n",
    "plt.show() \n",
    "\n",
    "#creating pie chart source:\n",
    "#https://www.w3schools.com/python/matplotlib_pie_charts.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec38dc5-f230-4277-a9f7-836cd5420ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global availabilty to be popular\n",
    "global_df= duckdb.sql(\"\"\"SELECT *\n",
    "FROM netflix_ratings_df\n",
    "WHERE Global== 'Yes'\"\"\").df()\n",
    "global_and_popular= (global_df[\"Popularity\"]==1).sum()\n",
    "global_and_not_popular= (global_df[\"Popularity\"]==0).sum()\n",
    "\n",
    "y = np.array([global_and_popular, global_and_not_popular])\n",
    "mylabels = [f\"Popular ({global_and_popular} Films)\", f\"Not Popular ({global_and_not_popular} Films)\"]\n",
    "\n",
    "plt.pie(y, labels = mylabels)\n",
    "plt.title(\"Popularity For Globally Available Films\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f9d426-712e-4289-b601-679c79038cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_global_df= duckdb.sql(\"\"\"SELECT *\n",
    "FROM netflix_ratings_df\n",
    "WHERE Global== 'No'\"\"\").df()\n",
    "not_global_and_popular= (not_global_df[\"Popularity\"]==1).sum()\n",
    "not_global_and_not_popular= (not_global_df[\"Popularity\"]==0).sum()\n",
    "\n",
    "y = np.array([not_global_and_popular, not_global_and_not_popular])\n",
    "mylabels = [f\"Popular ({not_global_and_popular} Films)\", f\"Not Popular ({not_global_and_not_popular} Films)\"]\n",
    "\n",
    "plt.pie(y, labels = mylabels)\n",
    "plt.title(\"Popularity For Non-Globally Available Films\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bed7f3-7fff-43ad-875c-a841434c74b2",
   "metadata": {},
   "source": [
    "First, out of the most 100 most viewed films in our dataset, approximately 2/3 of them are globally available and 1/3 are not globally available.\n",
    "Second, when only considering the globally available films, around 1/3 are popular.\n",
    "Third, when considering only the non-globally available films, around 0.16 are popular."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd32329d-efcb-4bb2-9223-2da37cbab202",
   "metadata": {},
   "source": [
    "# __Questions for Reviewers:__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1348566-d3c2-43fb-a7bf-c66542aedefa",
   "metadata": {},
   "source": [
    "How can we improve the merge of the netflix films and the IMDb ratings? There is certainly variation in the way that films are listed across the two sources, which causes us to have more missing ratings than what exists. Currently, we are joining by title after removing the foreign language and (year) parts of the netflix titles, but are there other actions we can take?\n",
    "\n",
    "Based on our current exploratory data analyses, do you think any analyses are especially suitable and recommended to move forwards with for phase 3? What additional work are we expected to do to bring our phase 2 exploratory analysis to the futher stages?\n",
    "\n",
    "Are there other strong graphs we can make to explore our research question?\n",
    "\n",
    "Do we sufficiently address the problems/limitations through our data cleaning, and if not, any suggestions for how we can we further treat our dataset to reduce the data limitations?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
